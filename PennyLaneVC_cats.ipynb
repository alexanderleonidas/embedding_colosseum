{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test all the QIR techniques implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataLoader import MNISTDataLoader,CatsDataset\n",
    "from FRQI import FRQI\n",
    "from NEQR import NEQR\n",
    "from OQIM import OQIM\n",
    "\n",
    "from functions import visualize_images_grid\n",
    "from qiskit import Aer,transpile\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter initialitzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this number is changet the intervals of the layer function need to be changed\n",
    "num_pixels = [16]\n",
    "input_images = []\n",
    "dataset = 'cats'\n",
    "\n",
    "#set parameters for the simulation\n",
    "numOfShots = 8000\n",
    "method = 'FRQI'\n",
    "printTime = False\n",
    "sim_bool = False\n",
    "backend = Aer.get_backend('qasm_simulator')\n",
    "measure_bool = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and visualize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'cats':\n",
    "    for pixels in num_pixels:\n",
    "        loader = CatsDataset('datasets/train_catvnoncat.h5')\n",
    "        X_train, Y_train, X_test, Y_test, classes = loader.load_and_resize_images(size=(pixels, pixels))\n",
    "else:\n",
    "    for pixels in num_pixels:\n",
    "        data_loader = MNISTDataLoader()\n",
    "        train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig = data_loader.load_and_resize_images(pixels=pixels)\n",
    "        X_train,Y_train = data_loader.select_classes(train_set_x_orig,train_set_y_orig,3,6)\n",
    "        X_test,Y_test = data_loader.select_classes(test_set_x_orig,test_set_y_orig,3,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 1\n",
    "visualize_images_grid(num_pixels,num_rows, [X_train[2]],numOfShots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the quantum circuit\n",
    "\n",
    "This is the circuit that we need to convert the classical image to a quantum state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "\n",
    "N = int(numpy.log2(num_pixels[0]))\n",
    "pos_qubits = 2 * N\n",
    "if method == 'FRQI':\n",
    "    num_qubits = pos_qubits+1\n",
    "elif method == 'NEQR':\n",
    "    num_qubits = pos_qubits+8\n",
    "elif method == 'OQIM':\n",
    "    num_qubits = pos_qubits+2\n",
    "elif method == 'default':\n",
    "    #for amplitud encoding we needd at least log2(pixels)\n",
    "    num_qubits = 2**N\n",
    "print(\"For an image of \"+str(num_pixels[0]*num_pixels[0]) +\" pixels we need \"+ str(num_qubits) +\" qubits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(W):\n",
    "    for wire in range(num_qubits):\n",
    "        qml.Rot(*W[wire], wires=wire)\n",
    "\n",
    "    #for wires in ([0, 1], [1, 2], [2, 3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9], [9, 0]):\n",
    "    entangling_gates = [(i, (i + 1) % num_qubits) for i in range(num_qubits)] \n",
    "    for wires in entangling_gates:\n",
    "        qml.CNOT(wires)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_preparation(x):\n",
    "\n",
    "    if method == 'FRQI':\n",
    "        frqi = FRQI()\n",
    "        circuit = frqi._create_FRQI_circ(x, measure_bool=False, printTime=printTime)\n",
    "        qml.from_qiskit(circuit)()\n",
    "    elif method == 'NEQR':\n",
    "        neqr = NEQR()\n",
    "        circuit = neqr._create_NEQR_circ(x, measure_bool=False, printTime=printTime)\n",
    "        circuit = circuit.decompose().decompose()\n",
    "        qml.from_qiskit(circuit)()\n",
    "    elif method == 'OQIM':\n",
    "        oqim = OQIM()\n",
    "        circuit = oqim.create_OQIM_circ(x, measure_bool=False, printTime=printTime)\n",
    "        qml.from_qiskit(circuit)()\n",
    "    elif method =='default':\n",
    "        qml.AmplitudeEmbedding(features=x,wires=range(num_qubits),pad_with = 0.)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"qiskit.aer\", wires=num_qubits)\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    state_preparation(x)\n",
    "\n",
    "    for layer_weights in weights:\n",
    "        layer(layer_weights)\n",
    "\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    # We use a call to qml.math.stack to allow subtracting the arrays directly\n",
    "    return np.mean((labels - qml.math.stack(predictions)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
    "    acc = acc / len(labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "'''print(\"Weights:\", weights_init)\n",
    "print(\"Bias: \", bias_init)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "if method == 'default':\n",
    "    X_train = np.array(X_train, requires_grad=False)\n",
    "    X_train = preprocessing.normalize(X_train)\n",
    "    X_test = np.array(X_test, requires_grad=False)\n",
    "    X_test = preprocessing.normalize(X_test)\n",
    "else:\n",
    "     X_train = np.array(X_train, requires_grad=False)\n",
    "     X_test = np.array(X_test, requires_grad=False)\n",
    "\n",
    "Y_train = np.array([1 if x == 1 else -1 for x in Y_train],requires_grad=False)\n",
    "Y_test = np.array([1 if x == 1 else -1 for x in Y_test],requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = NesterovMomentumOptimizer(0.5)\n",
    "num_it = 20\n",
    "batch_size = 5\n",
    "batch_train_size = 50\n",
    "\n",
    "acc_train = []\n",
    "costs = []\n",
    "acc_val = []\n",
    "\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(num_it):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
    "    X_batch = X_train[batch_index]\n",
    "    Y_batch = Y_train[batch_index]\n",
    "    weights, bias,_,_ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    batch_index_train = np.random.randint(0, len(X_train), (batch_train_size,))\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X_train[batch_index_train]]\n",
    "    #acc = accuracy(Y_train, predictions)\n",
    "    accTrain = accuracy(Y_train[batch_index_train],predictions)\n",
    "    acc_train.append(accTrain)\n",
    "    _cost = cost(weights,bias,X_train[batch_index_train],Y_train[batch_index_train])\n",
    "    costs.append(_cost)\n",
    "\n",
    "    if(it + 1)%2 == 0:\n",
    "        print(f\"Iter: {it+1:5d} | Cost: {_cost:0.7f} | Acc train: {accTrain:0.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(Y_test, predictions))\n",
    "print(precision_score(Y_test, predictions))\n",
    "print(recall_score(Y_test, predictions))\n",
    "print(f1_score(Y_test, predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(acc_train, label='Train accurancy')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Train accuracy using NEQR technique\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs, label='Cost')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Cost using NEQR technique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QIR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
